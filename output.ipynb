{"nbformat": 4, "nbformat_minor": 0, "metadata": {"anaconda-cloud": {}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.1"}}, "cells": [{"cell_type": "code", "metadata": {}, "source": ["\"\"\"\n", "\tImports -\n", "\"\"\"\n", "# Tensorflow 2.x\n", "import tensorflow as tf\n", "from tensorflow.keras import *\n", "\n", "# also for matrix computations\n", "import numpy\n", "\n", "# for viewing images and graphs\n", "import matplotlib.pyplot as plt"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["import tensorflow_datasets as tfds\n", "raw_data,info = tfds.load('mnist',split=['train','test'],with_info=True)\n", "\n", "print(info)"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# Input image size\n", "image_dimensions = (32,32,3)\n", "\n", "# Number of filter for Convolution layers\n", "conv_layers_dimensions = [256,128,64,32]\n", "# Number of \"Neurons\" for Dense layers\n", "dense_layers_dimensions = [256,10]\n", "\n", "def get_model():\n", "\n", "\tinputs = layers.Input(image_dimensions)\n", "\n", "\t# Input Normalization\n", "\tout = layers.BatchNormalization()(inputs)\n", "\n", "\tfor dims in conv_layers_dimensions:\n", "\t\tout = layers.Conv(dims , (3,3) , activation=\"relu\")(out)\n", "\t\t# Reduce heigth and width of each filter\n", "\t\tout = layers.MaxPool()(out)\n", "\n", "\tfor dims in dense_layers_dimensions[:-1]:\n", "\t\tlayers.Dense( dims , activation=\"relu\")\n", "\n", "\toutputs = layers.Dense( dense_layers_dimensions[-1] , activation=\"softmax\" )\n", "\n", "# Maps `inputs` to `outputs` to construct a model\n", "model = Model(inputs,outputs)"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["@tf.function\n", "def train_step(x, y):\n", "    \n", "    with tf.GradientTape() as tape:\n", "        logits = model(x, training=True)\n", "        loss_value = loss_fn(y, logits)\n", "    \n", "    grads = tape.gradient(loss_value, model.trainable_weights)\n", "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n", "    train_acc_metric.update_state(y, logits)\n", "    \n", "    return loss_value\n", "\n", "\n", "epochs = 10\n", "\n", "for epoch in range(epochs):\n", "\n", "    start_time = time.time()\n", "\n", "    # Iterate over the batches of the dataset.\n", "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n", "\n", "        loss_value = train_step(x_batch_train, y_batch_train)\n", "\n", "        # Log every 200 batches.\n", "        if step % 200 == 0:\n", "            print(\n", "                \"Training loss (for one batch) at step %d: %.4f\"\n", "                % (step, float(loss_value))\n", "            )\n", "            print(\"Seen so far: %d samples\" % ((step + 1) * 64))\n", "\n", "    # Display metrics at the end of each epoch.\n", "    train_acc = train_acc_metric.result()\n", "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n", "\n", "    # Reset training metrics at the end of each epoch\n", "    train_acc_metric.reset_states()\n", "\n", "    # Run a validation loop at the end of each epoch.\n", "    for x_batch_val, y_batch_val in val_dataset:\n", "        test_step(x_batch_val, y_batch_val)\n", "\n", "    val_acc = val_acc_metric.result()\n", "    val_acc_metric.reset_states()\n", "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n", "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"], "outputs": [], "execution_count": null}]}